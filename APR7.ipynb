{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOvY2CoSIQZiJXHLYq+SQsv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# TL07 Regularización"],"metadata":{"id":"xEv8rWluAsb4"}},{"cell_type":"markdown","source":["Propósito: evitar modelos sobreajustados modificando el comportamiento de descenso por gradiente, objetivo y datos"],"metadata":{"id":"xw_zMQBGAzf1"}},{"cell_type":"markdown","source":["## Inicialización: librerías, semilla, lectura de MNIST sin normalización y partición train-val-test"],"metadata":{"id":"tCm_dHhZBR8M"}},{"cell_type":"code","source":["pip install keras_tuner"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F24T-1oCBlr3","executionInfo":{"status":"ok","timestamp":1733674055437,"user_tz":-60,"elapsed":4003,"user":{"displayName":"Cristina Rodríguez","userId":"01742615235766394237"}},"outputId":"9f559b9e-927c-40d4-b803-99f2ee54f028"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting keras_tuner\n","  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (3.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (24.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.32.3)\n","Collecting kt-legacy (from keras_tuner)\n","  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (3.12.1)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.13.1)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.8.30)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras_tuner) (4.12.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_tuner) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_tuner) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n","Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m92.2/129.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n","Installing collected packages: kt-legacy, keras_tuner\n","Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u3D3pfh8AnAa","executionInfo":{"status":"ok","timestamp":1733674065310,"user_tz":-60,"elapsed":4167,"user":{"displayName":"Cristina Rodríguez","userId":"01742615235766394237"}},"outputId":"e6a3f751-eca9-4c5f-8fa3-b21d5900bed1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","(60000, 28, 28, 1) (60000,) (10000, 28, 28, 1) (10000,)\n"]}],"source":["import numpy as np; import matplotlib.pyplot as plt\n","import os; os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","import keras; import keras_tuner\n","keras.utils.set_random_seed(23); input_dim = (28, 28, 1); num_classes = 10\n","(x_train_val, y_train_val), (x_test, y_test) = keras.datasets.mnist.load_data()\n","x_train_val = x_train_val.astype(\"float32\")\n","x_test = x_test.astype(\"float32\")\n","x_train_val = np.expand_dims(x_train_val, -1)\n","x_test = np.expand_dims(x_test, -1)\n","print(x_train_val.shape, y_train_val.shape, x_test.shape, y_test.shape)\n","y_train_val = keras.utils.to_categorical(y_train_val, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","x_train = x_train_val[:-10000]; x_val = x_train_val[-10000:]\n","y_train = y_train_val[:-10000]; y_val = y_train_val[-10000:]"]},{"cell_type":"markdown","source":["MyHyperModel: exploramos aumento de datos (rotación, translación y zoom) y dropout 0.5"],"metadata":{"id":"e9vHYL4lBgFq"}},{"cell_type":"code","source":["class MyHyperModel(keras_tuner.HyperModel):\n","  def build(self, hp):\n","      M = keras.Sequential()\n","      M.add(keras.Input(shape=(28, 28, 1)))\n","      factor = hp.Float(\"factor\", min_value=0.01, max_value=0.3, step=2, sampling=\"log\")\n","      M.add(keras.layers.RandomRotation(factor, fill_mode=\"nearest\"))\n","      M.add(keras.layers.RandomTranslation(factor, factor, fill_mode=\"nearest\"))\n","      M.add(keras.layers.RandomZoom(factor, fill_mode=\"nearest\"))\n","      M.add(keras.layers.Rescaling(1./255))\n","      filters = 64\n","      M.add(keras.layers.Conv2D(filters, kernel_size=(3, 3), activation=\"relu\"))\n","      M.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","      M.add(keras.layers.Conv2D(2*filters, kernel_size=(3, 3), activation=\"relu\"))\n","      M.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","      M.add(keras.layers.Flatten())\n","      M.add(keras.layers.Dense(units=800, activation='relu'))\n","      # dropout = hp.Float(\"dropout\", min_value=0.0, max_value=0.5, step=0.1)\n","      dropout = 0.5\n","      M.add(keras.layers.Dropout(dropout))\n","      M.add(keras.layers.Dense(10, activation='softmax'))\n","      opt = keras.optimizers.Adam(learning_rate=0.00168)\n","      M.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","      return M\n","  def fit(self, hp, M, x, y, xy_val, **kwargs):\n","      factor = 0.3787; patience = 5\n","      reduce_cb = keras.callbacks.ReduceLROnPlateau(\n","      monitor='val_accuracy', factor=factor, patience=patience, min_delta=1e-4, min_lr=1e-5)\n","      early_cb = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2*patience, min_delta=1e-5)\n","      kwargs['callbacks'].extend([reduce_cb, early_cb])\n","      return M.fit(x, y, batch_size=256, epochs=100, validation_data=xy_val, **kwargs)"],"metadata":{"id":"9plx54OlBj01","executionInfo":{"status":"ok","timestamp":1733674086036,"user_tz":-60,"elapsed":241,"user":{"displayName":"Cristina Rodríguez","userId":"01742615235766394237"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Experimento: exploración y resumen de resultados"],"metadata":{"id":"2GnykKRiB2i6"}},{"cell_type":"code","source":["tuner = keras_tuner.BayesianOptimization(\n","  MyHyperModel(), objective=\"val_accuracy\", max_trials=10, executions_per_trial=1,\n","  overwrite=True, directory=\"/tmp\", project_name=\"MNIST\")\n"],"metadata":{"id":"wQPTcXe4B4P_","executionInfo":{"status":"ok","timestamp":1733674112351,"user_tz":-60,"elapsed":908,"user":{"displayName":"Cristina Rodríguez","userId":"01742615235766394237"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["tuner.search(x_train, y_train, (x_val, y_val))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mhnfEUdVB6px","outputId":"ae56f86d-9aee-42b9-ebfe-bf4acad59047"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Search: Running Trial #1\n","\n","Value             |Best Value So Far |Hyperparameter\n","0.04              |0.04              |factor\n","\n","Epoch 1/100\n","\u001b[1m 66/196\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 769ms/step - accuracy: 0.6845 - loss: 0.9475"]}]},{"cell_type":"code","source":["tuner.results_summary(num_trials=3)"],"metadata":{"id":"VrcPVXszB9aB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Experimento (cont.): evaluación en test de los mejores modelos en validación"],"metadata":{"id":"_Zjdve0OCBof"}},{"cell_type":"code","source":["num_models = 10\n","best_hyperparameters = tuner.get_best_hyperparameters(num_trials=num_models)\n","best_models = tuner.get_best_models(num_models=num_models)\n","for m in range(num_models):\n","    values = best_hyperparameters[m].values\n","    score = best_models[m].evaluate(x_test, y_test, verbose=0)\n","    print(f'Model {m}: Hyperparameters: {values!s} Loss: {score[0]:.4} Precisión: {score[1]:.2%}')"],"metadata":{"id":"grZrWffRCBXQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ejercicio: realiza un experimento similar al de MNIST con Fashion-MNIST"],"metadata":{"id":"HJDf2OYeCXfQ"}},{"cell_type":"markdown","source":["Inicialización: librerías, semilla, lectura de Fashion-MNIST sin normalización y partición train-val-test\n"],"metadata":{"id":"3fhVjZpLCbCq"}},{"cell_type":"code","source":["import numpy as np; import matplotlib.pyplot as plt\n","import os; os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","import keras; import keras_tuner\n","keras.utils.set_random_seed(23); input_dim = (28, 28, 1); num_classes = 10\n","(x_train_val, y_train_val), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n","x_train_val = x_train_val.astype(\"float32\")\n","x_test = x_test.astype(\"float32\")\n","x_train_val = np.expand_dims(x_train_val, -1)\n","x_test = np.expand_dims(x_test, -1)\n","print(x_train_val.shape, y_train_val.shape, x_test.shape, y_test.shape)\n","y_train_val = keras.utils.to_categorical(y_train_val, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","x_train = x_train_val[:-10000]; x_val = x_train_val[-10000:]\n","y_train = y_train_val[:-10000]; y_val = y_train_val[-10000:]\n"],"metadata":{"id":"kPN5MQK9CdCr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MyHyperModel: exploramos aumento de datos (rotación, translación y zoom) y dropout 0.5"],"metadata":{"id":"HzG6xOFVCf4w"}},{"cell_type":"code","source":["class MyHyperModel(keras_tuner.HyperModel):\n","  def build(self, hp):\n","      M = keras.Sequential()\n","      M.add(keras.Input(shape=(28, 28, 1)))\n","      factor = hp.Float(\"factor\", min_value=0.01, max_value=0.3, step=2, sampling=\"log\")\n","      M.add(keras.layers.RandomRotation(factor, fill_mode=\"nearest\"))\n","      M.add(keras.layers.RandomTranslation(factor, factor, fill_mode=\"nearest\"))\n","      M.add(keras.layers.RandomZoom(factor, fill_mode=\"nearest\"))\n","      M.add(keras.layers.Rescaling(1./255))\n","      filters = 64\n","      M.add(keras.layers.Conv2D(filters, kernel_size=(3, 3), activation=\"relu\"))\n","      M.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","      M.add(keras.layers.Conv2D(2*filters, kernel_size=(3, 3), activation=\"relu\"))\n","      M.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","      M.add(keras.layers.Flatten())\n","      M.add(keras.layers.Dense(units=800, activation='relu'))\n","      # dropout = hp.Float(\"dropout\", min_value=0.0, max_value=0.5, step=0.1)\n","      dropout = 0.5\n","      M.add(keras.layers.Dropout(dropout))\n","      M.add(keras.layers.Dense(10, activation='softmax'))\n","      opt = keras.optimizers.Adam(learning_rate=0.00015)\n","      M.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","      return M\n","  def fit(self, hp, M, x, y, xy_val, **kwargs):\n","      factor = 0.32; patience = 5\n","      reduce_cb = keras.callbacks.ReduceLROnPlateau(\n","      monitor='val_accuracy', factor=factor, patience=patience, min_delta=1e-4, min_lr=1e-5)\n","      early_cb = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2*patience, min_delta=1e-5)\n","      kwargs['callbacks'].extend([reduce_cb, early_cb])\n","      return M.fit(x, y, batch_size=256, epochs=100, validation_data=xy_val, **kwargs)\n"],"metadata":{"id":"xxNkOs1eCiOW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Experimento: exploración y resumen de resultados"],"metadata":{"id":"4DrjMDZ5C-F6"}},{"cell_type":"code","source":["tuner = keras_tuner.BayesianOptimization(\n","  MyHyperModel(), objective=\"val_accuracy\", max_trials=10, executions_per_trial=1,\n","  overwrite=True, directory=\"/tmp\", project_name=\"Fashion-MNIST\")"],"metadata":{"id":"DntKf365C_7z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner.search(x_train, y_train, (x_val, y_val))"],"metadata":{"id":"-D_gel_TDCe-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner.results_summary(num_trials=3)"],"metadata":{"id":"f-ubo_2GDEkP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_models = 10\n","best_hyperparameters = tuner.get_best_hyperparameters(num_trials=num_models)\n","best_models = tuner.get_best_models(num_models=num_models)\n","for m in range(num_models):\n","  values = best_hyperparameters[m].values\n","  score = best_models[m].evaluate(x_test, y_test, verbose=0)\n","  print(f'Model {m}: Hyperparameters: {values!s} Loss: {score[0]:.4} Precisión: {score[1]:.2%}')\n"],"metadata":{"id":"rDJDlXICDHFY"},"execution_count":null,"outputs":[]}]}